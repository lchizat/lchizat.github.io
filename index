# jemdoc: menu{MENU}{index.html}, analytics{UA-65279943-1}
= Lénaïc Chizat
CNRS researcher at Laboratoire de Mathématiques d'Orsay

~~~
{}{img_left}{files/photo.png}{photo de lenaic}{WIDTHpx}{220px}{files/photo.png}


I am a [https://www.cnrs.fr/en CNRS] researcher at [https://www.math.u-psud.fr/ LMO], the math department of Université Paris-Sud. In 2018, I was a post-doc researcher at INRIA Paris working with [https://www.di.ens.fr/~fbach/ Francis Bach]. In 2017, I have completed a PhD in applied mathematics at Université Paris-Dauphine (CEREMADE) and École Normale Supérieure (DMA) working with [http://gpeyre.github.io/ G. Peyré] and [https://www.ceremade.dauphine.fr/~vialard/ F-X. Vialard]. 

I am interested in the mathematical analysis of data-driven algorithms. More specifically I have worked on the following topics:
- optimal transport and variational problems in the space of measures
- continuous optimization algorithms (convex and non-convex)
- applications to machine learning and signal processing
~~~

~~~
{}{img_left}{files/email.png}{my email}{WIDTHpx}{20px}{files/email.png}
~~~

== Recent news
- (14-01-2020) Gave a tutorial on *Optimal Transport Theory for Machine learning* at the Indian Statistical Institute, Kolkata \[[files/presentations/chizat2020ISI.pdf slides]\]. It was part of the workshop on [https://www.isical.ac.in/~caiml/stat-ai-data-science/ Statistics and Artificial Intelligence for Data Science].

- (09-01-2020) Gave a talk on the *Analysis of Gradient Methods for Wide Two-Layer Neural  Networks* at ICTS, Bangalore \[[files/presentations/chizat2020ICTS.pdf slides]\]. It was part of the workshop on \[[https://www.icts.res.in/discussion-meeting/SPMML2020 Statistical physics of machine learning]\].

- (11-12-2019) Presented our poster *On Lazy Training in Differentiable Programming* at the NeurIPS 2019 conference at Vancouver. \[[files/posters/lazy2019poster.pdf poster]\] \[[https://arxiv.org/abs/1812.07956 paper]\].

- (05-12-2019) Gave a talk at the MAD seminar, Center for Data Science and Courant Institute, NYU and spent a wonderful week there hosted by Joan Bruna. \[ [https://nyursc.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=d4d1079c-debf-4353-a36b-aafc010d1e8b video]\]

- (28/11/2019) We prepared a *Tutorial on non-convex optimization with gradient methods* for the SMILE in Paris seminar \[[files/presentations/chizat191128smile.pdf slides part (II)]\] (see [https://guillaume-garrigos.com/ Guillaume Garrigos webpage] for part (I)).

- (26-11-2019) Participated to the *Optimization on Measure Space* workshop at the IMT, Toulouse, France. This was the occasion to present in detail my recent work on *Sparse optimization on Measures with over-parameterized gradient descent* \[[files/presentations/chizat191126toulouse.pdf slides]\], \[[https://arxiv.org/abs/1907.10300 paper]\].


== Teaching
- Machine learning - Master ICFP - ENS (lecture 2 : \[[files/cours_ML2020/cours2.pdf notes]\], \[[files/cours_ML2020/TD1.ipynb TD1]\], \[[files/cours_ML2020/mnist_digits.mat data TD1]\])

- Optimal Transport - Master Optimisation - Université Paris-Saclay


== Publications

2019

- L. Chizat. *Sparse Optimization on Measures with Over-parameterized Gradient Descent.* Technical report HAL-02190822, 2019. \[[https://hal.archives-ouvertes.fr/hal-02190822 pdf]\]

- L. Chizat, E.Oyallon, F. Bach. *On Lazy Training in Differentiable Programming.* To appear in Advances in Neural Information Processing Systems (NeurIPS), 2019. \[[https://hal.inria.fr/hal-01945578 pdf]\]

- A. Genevay, L. Chizat, F. Bach, M. Cuturi, G. Peyré. *Sample Complexity of Sinkhorn divergences.* Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS), 2019. \[[http://proceedings.mlr.press/v89/genevay19a/genevay19a.pdf pdf]\]

2018

- L. Chizat, F. Bach. *On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport.* Advances in Neural Information Processing Systems (NeurIPS), 2018. \[[https://hal.archives-ouvertes.fr/hal-01798792/document pdf]\] \[[files/posters/chizatbach2018poster.pdf poster]\]

- L. Chizat, G. Peyré, B. Schmitzer, F-X. Vialard, *Unbalanced Optimal Transport: Dynamic and Kantorovich formulations.* Journal of Functional Analysis, 2018. \[[https://www.sciencedirect.com/science/article/pii/S0022123618301058 article]\] \[[https://arxiv.org/abs/1508.05216 pdf]\]

- L. Chizat, G. Peyré, B. Schmitzer, F-X. Vialard,  *Scaling Algorithms for Unbalanced Optimal Transport Problems.* Mathematics of Computation, 2018.  \[[https://arxiv.org/abs/1607.05816 pdf]\]

2017

- A. Thibault, L. Chizat, C. Dossal, N. Papadakis, *Overrelaxed Sinkhorn-Knopp Algorithm for Regularized Optimal Transport.* Technical report, arXiv-1711.01851, presented at the NIPS 2017 Workshop on Optimal Transport & Machine Learning. \[[https://arxiv.org/abs/1711.01851 pdf]\]

- L. Chizat *Unbalanced Optimal Transport: Models, Numerical Methods, Applications.* PhD thesis, PSL Research University, 2017. \[[https://tel.archives-ouvertes.fr/tel-01881166/document pdf]\]

- L. Chizat, S. Di Marino, *A tumor growth model of Hele-Shaw type as a gradient flow.* Technical report, arXiv-1712.06124, 2017. \[[https://arxiv.org/abs/1712.06124 pdf]\]

- G. Peyré, L. Chizat , F-X. Vialard, J. Solomon, *Quantum Optimal Transport for Tensor Field Processing.* European Journal of Applied Mathematics, 2017. \[[https://arxiv.org/abs/1612.08731 pdf]\]


2016

- L. Chizat, G. Peyré, B. Schmitzer, F-X. Vialard, *An Interpolating Distance Between Optimal Transport and Fisher–Rao Metrics*, Foundations of Computational Mathematics, 2016. \[[https://arxiv.org/pdf/1506.06430.pdf pdf]\]

== Selection of talks with slides
Slides sometimes include videos that can be read with Adobe Acrobat (try to click on any image).
- 11/2019 *Tutorial on non-convex optimization with gradient methods (II).* (see [https://guillaume-garrigos.com/ Guillaume Garrigos webpage] for part (I)), SMILE in Paris seminar \[[files/presentations/chizat191128smile.pdf slides]\]
- 11/2019 *Optimization on Measures with Over-parameterized Gradient Descent.* Optimization on Measures workshop, IMT Toulouse \[[files/presentations/chizat191126toulouse.pdf slides]\]
- 11/2019 *Two analyses for of gradient-based optimization for wide two-layer neural networks.* Theory of Neural Networks seminar, EPFL \[[files/presentations/chizat191105epfl.pdf slides]\]
- 07/2019 *Theoretical aspects of Neural Networks Optimization.* IISc Bangalore. \[[files/presentations/chizat2019IFCAM_NN.pdf slides]\] \[[files/presentations/chizat2019IFCAM_NN.zip download slides with animations]\]
- 07/2019 *Tutorial on Optimal Transport with a Machine Learning Touch.* IISc Bangalore. \[[files/presentations/chizat2019IFCAM_OT.pdf slides]\] \[[files/presentations/chizat2019IFCAM_OT.zip download slides with animations]\]
- 07/2018 *On the Global Convergence of Gradient Descent for Over-parameterized Models.* IFIP conference in Essen. \[[files/chizat2018ifip.zip download slides with animations]\]
- 02/2018 *A Tutorial on Optimal Transport* with A. Genevay at [https://imaging-in-paris.github.io/seminar/ Imaging in Paris]. \[[files/CHIZAT_imagingParis_080218.pdf slides]\]
- 11/2017 *Unbalanced Optimal Transport.* PhD Defense at Université Paris Dauphine. \[[files/CHIZAT_soutenance.pdf slides in French]\] \[[chizat2017phddefense.pdf slides in English]\]
- 09/2017 *A Primer on Optimal Transport*, talk at the [https://www.broadinstitute.org/ Broad institute]'s [https://www.broadinstitute.org/scientific-community/science/mia/models-inference-algorithms MIA seminar] (MIT-Harvard). \[[https://www.youtube.com/watch?v=vJx7NiXFMi8 watch video]\].

