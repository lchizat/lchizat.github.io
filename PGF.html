<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Particle gradient flows</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Lénaïc Chizat</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="curriculum.html">Curriculum</a></div>
<div class="menu-item"><a href="talks.html">Talks&nbsp;&amp;&nbsp;Organization</a></div>
<div class="menu-item"><a href="https://github.com/lchizat">Code</a></div>
<div class="menu-category">Projects</div>
<div class="menu-item"><a href="PGF.html" class="current">Gradient&nbsp;flows</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Particle gradient flows</h1>
</div>
<div class="infoblock">
<div class="blocktitle">Preprint</div>
<div class="blockcontent">
<p>Lenaic Chizat, Francis Bach. On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport. 2018. 〈hal-01798792〉</p>
</div></div>
<p>We display on below animated versions of the particle gradient flows shown in Section 4 of the preprint, as well as a particle gradient flow corresponding to the training of a neural network with a single hidden layer and sigmoid activation function in dimension d=2. In all these cases, the global minimizer (supported on the dotted lines in the plots) is found. The time scale is logarithmic.</p>
<table class="imgtable"><tr><td>
<a href="files/PGFspikes.gif"><img src="files/PGFspikes.gif" alt="spikes deconvolution" width="WIDTHpx" height="220px" /></a>&nbsp;</td>
<td align="left"><p>Sparse spikes deconvolution, with position shown horizontally and weight shown vertically.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="files/PGFrelu.gif"><img src="files/PGFrelu.gif" alt="ReLU activation" width="WIDTHpx" height="220px" /></a>&nbsp;</td>
<td align="left"><p>Neural network with ReLU activation function: we show for each particle the trajectory \(\vert w(t)\vert\cdot \theta(t)\in \mathbb{R}^2\).</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="files/PGFsigmoid.gif"><img src="files/PGFsigmoid.gif" alt="sigmoid activation" width="WIDTHpx" height="220px" /></a>&nbsp;</td>
<td align="left"><p>neural network with sigmoid activation function, with weights represented by the size of the particles (blue for negative, red for positive, ground truth shown with 2 neurons shown by large disks)</p>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2018-05-23 22:49:44 CEST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
